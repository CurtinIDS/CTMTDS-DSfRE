{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c7db46",
   "metadata": {},
   "source": [
    "<img src=\"../assets/ittc_logo_full.png\" height=150>\n",
    "\n",
    "# Lecture 4 Practical: Data Cleaning\n",
    "\n",
    "## In this practical\n",
    "\n",
    "In this practical you will:\n",
    "\n",
    "1. Learn how to clean data\n",
    "2. Search for outliers using automated methods\n",
    "3. Merge tables both horizontally and vertically\n",
    "4. Resample time series data onto new frequencies\n",
    "\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # Plottling library used for BoxPlots\n",
    "\n",
    "concrete = pd.read_csv(\"../data/concrete.csv\")\n",
    "chemical = pd.read_csv(\"../data/chemicalmanufacturingprocess.csv\", skiprows=1)\n",
    "backblaze = pd.read_parquet(\"../data/backblaze.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9edb6",
   "metadata": {},
   "source": [
    "## 1. Identifying Outliers\n",
    "\n",
    "### 1.1 Concrete outliers\n",
    "\n",
    "We will start by using a **box plot** on the `CompressiveStrength` field for the concrete to explore the distribution of values.\n",
    "\n",
    "A box plot provides a visual guide to the distribution and skew of a data set:\n",
    "\n",
    "* The lower and upper edges of the box indicate the 1st and 3rd **quartiles** of the data\n",
    "* The central (orange) line indicates the **median**\n",
    "* The whiskers indicate 3x the **interquartile range**\n",
    "* **Outliers** beyond this range are indicated by individual points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(concrete[\"CompressiveStrength\"], whis=3, tick_labels=[\"Compressive Strength\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306bf9e",
   "metadata": {},
   "source": [
    "**Observation:** It is clear that there is one outlier value that is far stronger than the general population.\n",
    "\n",
    "After discussions with engineers who gathered this data, it turns out this value is incorrect.\n",
    "\n",
    "We need to remove this data point, and to do so we're going to use two methods:\n",
    "\n",
    "1. Manually identify and remove the outlier\n",
    "2. An automated method using the interquartile range\n",
    "\n",
    "#### 1.1 Manual excision\n",
    "\n",
    "First, identify the row with the outlier value. Use `.query()` to select the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = concrete.query(\"...\").index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e7bd1",
   "metadata": {},
   "source": [
    "Then we can use the method `.drop(rowidx)` to remove the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete.drop(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338593d",
   "metadata": {},
   "source": [
    "**Note:** `.drop(()` returns a _new_ DataFrame with the row removed; it will not alter the original DataFrame unless you pass the keyword argument `inplace=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0845768",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81f77e7b",
   "metadata": {},
   "source": [
    "### 1.2 Automated excision\n",
    "\n",
    "Manually eyeballing outliers is not practical on a large dataset. A better way to do this is to identify outliers in an automated fashion.\n",
    "\n",
    "Let's use the 3x the interquartile range as a reasonable bound on our data and drop values that lie outside this range.\n",
    "\n",
    "First, let's calculate the median and interquartile range using `quantile()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bc096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1, median, q3 = concrete[\"CompressiveStrength\"].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# iqr = ...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87b752",
   "metadata": {},
   "source": [
    "Using these values let's use the `.query()` method to filter the DataFrame to those rows with a CompressiveStength less than a factor 3x the IQR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af482dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concretefiltered = concrete.query(\"(@median - 3 * @iqr) < CompressiveStrength < ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1515c89",
   "metadata": {},
   "source": [
    "Finally, let's visualise our dataset again using the boxplot to confirm the results of our outlier detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b5065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.boxplot(concretefiltered[\"CompressiveStrength\"], whis=3, tick_labels=[\"CompressiveStrength\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce025f2",
   "metadata": {},
   "source": [
    "### 1.3 Chemical Manufacturing Process\n",
    "\n",
    "The data stored in `chemical` DataFrame also has some outliers associated with its Yield column. In this exercise:\n",
    "\n",
    "1. Make a boxplot of the Yield\n",
    "2. Manually identify the outliers and use `.query()` and `.drop()` to excise the data\n",
    "3. Use the interquartile range to automate the removal of these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean your data here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc083e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03f64e29",
   "metadata": {},
   "source": [
    "## 2. Merging tables\n",
    "\n",
    "### 2.1 Vertical concatenation\n",
    "\n",
    "You receive a new set of concrete data located at `../data/concrete-2.csv`.\n",
    "\n",
    "**Aim:** combine this table with the original concrete data.\n",
    "\n",
    "First, load the new data as a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concrete2 = pd.read_csv(\"...\")\n",
    "# display(concrete2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f882542",
   "metadata": {},
   "source": [
    "These tables have an identical set of column, so you can \"stack\" tables using the function `pd.concat([tbl1, ...])`.\n",
    "\n",
    "Combine `concrete` and `concrete2` using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b743630",
   "metadata": {},
   "source": [
    "**Question:** what is the shape of the combined table?\n",
    "\n",
    "### 2.2 Horizontal merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed46792",
   "metadata": {},
   "source": [
    "First let's note the different models of drive that we have in our data using `.unique()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acace2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backblaze[\"model\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0041734",
   "metadata": {},
   "source": [
    "Let's load the data about each of these models from the CSV located at `../data/backblaze-models.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c660c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = pd.read_csv(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a7ace",
   "metadata": {},
   "source": [
    "We want to merge these tables: for every row in the original `backblaze` DataFrame, we want to include this additional data about the drive.\n",
    "\n",
    "We do this using a `pd.merge()`:\n",
    "\n",
    "* Specify both the \"left\" and \"right\" tables to be merged\n",
    "* Using the keyword parameters `left_on` and `right_on`, specify the column from each table that will be used to match the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(..., ..., left_on=\"...\", right_on=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca209a3",
   "metadata": {},
   "source": [
    "Suppose we're only interested in the operating power from the `models` DataFrame.\n",
    "\n",
    "Try merging _only_ the `operating_power` column.\n",
    "\n",
    "(**Hint:** remember we can select a subset of columns with the syntax `df[[\"col1\", \"col2\"]]` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(..., ..., left_on=\"...\", right_on=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395616b",
   "metadata": {},
   "source": [
    "## 3. Resampling\n",
    "\n",
    "For this section we return to the Backblaze data.\n",
    "\n",
    "Each row in this table represents a daily \"health check\" for every harddrive in operation. Eventually, when a drive fails its final daily health check will set `failure=1`. That is, every entry where `failure=1` represents a drive failing.\n",
    "\n",
    "**Our goal:** track the number of drives failing over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e3c70",
   "metadata": {},
   "source": [
    "### 3.1 Setting the index\n",
    "\n",
    "The first step to resampling the backblaze data is to set the index correctly: currently the index is just the row number, but we need the index to be the date.\n",
    "\n",
    "To make this change, we use the `.set_index()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e20fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "backblaze.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d4104",
   "metadata": {},
   "source": [
    "You can see that the index column is now set as `date`. Remember that this method returns a new copy of the DataFrame; it does not change the original backblaze DataFrame unless the keyword argument `inplace=True` is set.\n",
    "\n",
    "### 3.2 Daily failures\n",
    "\n",
    "Let's say we want to count the number of drive failures on a daily basis. To do this:\n",
    "\n",
    "1. Set the `date` column as the index\n",
    "2. Select the `failure` comlumn\n",
    "2. Resample this column to a daily basis and summing the number of failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ea784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set the date columnas the index\n",
    "backblaze_dateindex = backblaze.set_index(\"date\")\n",
    "\n",
    "# 2. Select the failure column\n",
    "failures = backblaze_dateindex[\"failure\"]\n",
    "\n",
    "# 3. Sum the failures for each day\n",
    "daily = failures.resample(\"1D\").sum()\n",
    "\n",
    "# OR: Use method chaining to do this as one line:\n",
    "daily = backblaze.set_index(\"date\")[\"failure\"].resample(\"1D\").sum()\n",
    "\n",
    "display(daily)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65463b59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07dc1d9b",
   "metadata": {},
   "source": [
    "We can now plot these failures over time using `plt.plot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222d8a4",
   "metadata": {},
   "source": [
    "### 3.3 Monthly failures\n",
    "\n",
    "The daily failures are every 'noisy': there's too much variation on a day-to-day basis.\n",
    "\n",
    "Your goal is to:\n",
    "\n",
    "1. Resample the data to a **monthly** basis and calculate the total drive failures across this period\n",
    "2. Create a new plot showing the monthly failure incidence.\n",
    "\n",
    "**Hint:** You can view all the resamping string codes [here.](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#period-aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e9178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e74850",
   "metadata": {},
   "source": [
    "## 4. Advanced\n",
    "\n",
    "Plot the sum operating power for each failed drive over a 7 day period.\n",
    "\n",
    "You will need to:\n",
    "\n",
    "* Merge the operating_power column from `models`\n",
    "* Filter rows to include `failure=1` only\n",
    "* Resample the data to a '7 day' period\n",
    "* Sum the operating_power and plot the resulting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
